{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import division\n",
    "import sqlite3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlitefile = 'data.sqlite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(sqlitefile)\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE sanders\n",
    "       (datetime       REAL,\n",
    "       sentiment      REAL,\n",
    "       tweetID        TEXT);''')\n",
    "c.execute('''CREATE TABLE trump\n",
    "       (datetime       REAL,\n",
    "       sentiment      REAL,\n",
    "       tweetID        TEXT);''')\n",
    "c.execute('''CREATE TABLE clinton\n",
    "       (datetime       REAL,\n",
    "       sentiment      REAL,\n",
    "       tweetID        TEXT);''')\n",
    "c.execute('''CREATE TABLE cruz\n",
    "       (datetime       REAL,\n",
    "       sentiment      REAL,\n",
    "       tweetID        TEXT);''')\n",
    "c.execute('''CREATE TABLE unknown\n",
    "       (datetime       REAL,\n",
    "       sentiment      REAL,\n",
    "       tweetID        TEXT);''')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b76711ab21d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     data = pd.read_csv('data_'+candidate+'_00000.csv', header=None,\n\u001b[0;32m      4\u001b[0m                    \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tweetID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                    dtype={'date': np.float64, 'sentiment': np.float64, 'tweetID': str})\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqlitefile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeroe\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    489\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeroe\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m _parser_defaults = {\n",
      "\u001b[1;32mc:\\Users\\jeroe\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeroe\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    225\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    226\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeroe\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_init_dict\u001b[1;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         return _arrays_to_mgr(arrays, data_names, index, columns,\n\u001b[1;32m--> 362\u001b[1;33m                               dtype=dtype)\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     def _init_ndarray(self, values, index, columns, dtype=None,\n",
      "\u001b[1;32mc:\\Users\\jeroe\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m   5100\u001b[0m     \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_ensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeroe\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[1;34m(arrays, names, axes)\u001b[0m\n\u001b[0;32m   3798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3799\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3800\u001b[1;33m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mform_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3801\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3802\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeroe\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mform_blocks\u001b[1;34m(arrays, names, axes)\u001b[0m\n\u001b[0;32m   3867\u001b[0m     \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3868\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3869\u001b[1;33m         \u001b[0mfloat_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_multi_blockify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3870\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeroe\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_multi_blockify\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   3950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3951\u001b[0m         values, placement = _stack_arrays(\n\u001b[1;32m-> 3952\u001b[1;33m             list(tup_block), dtype)\n\u001b[0m\u001b[0;32m   3953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3954\u001b[0m         \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeroe\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   3994\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_shape_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3995\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3996\u001b[1;33m     \u001b[0mstacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3997\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3998\u001b[0m         \u001b[0mstacked\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "candidates = ['sanders', 'trump', 'clinton', 'cruz', 'unknown']\n",
    "for candidate in candidates:\n",
    "    data = pd.read_csv('data_'+candidate+'_00000.csv', header=None,\n",
    "                   names=['date', 'sentiment', 'tweetID'],\n",
    "                   dtype={'date': np.float64, 'sentiment': np.float64, 'tweetID': str})\n",
    "    conn = sqlite3.connect(sqlitefile)\n",
    "    c = conn.cursor()\n",
    "    c.executemany('''INSERT INTO '''+candidate+'''(datetime, sentiment, tweetID) VALUES (?, ?, ?)''', np.array(data))\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create downsampled database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlitefile_downsampled = 'data_downsampled.sqlite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(sqlitefile_downsampled)\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE sanders\n",
    "       (datetime      REAL,\n",
    "       sentiment      REAL,\n",
    "       tweet_count    INTEGER);''')\n",
    "c.execute('''CREATE TABLE trump\n",
    "       (datetime      REAL,\n",
    "       sentiment      REAL,\n",
    "       tweet_count    INTEGER);''')\n",
    "c.execute('''CREATE TABLE clinton\n",
    "       (datetime      REAL,\n",
    "       sentiment      REAL,\n",
    "       tweet_count    INTEGER);''')\n",
    "c.execute('''CREATE TABLE cruz\n",
    "       (datetime      REAL,\n",
    "       sentiment      REAL,\n",
    "       tweet_count    INTEGER);''')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_size = 30 * 60 # 30 minutes, in seconds\n",
    "min_tweets = 100 # minimum number of tweets for a valid entry\n",
    "\n",
    "candidates = ['sanders', 'trump', 'clinton', 'cruz']\n",
    "\n",
    "for candidate in candidates:\n",
    "    \n",
    "    conn = sqlite3.connect(sqlitefile_downsampled)\n",
    "    c = conn.cursor()\n",
    "#     c.execute('''DELETE FROM '''+candidate+''' WHERE 1=1''')\n",
    "#     conn.commit()\n",
    "    c.execute('''SELECT * FROM '''+candidate+''' LIMIT 1;''')\n",
    "    row = c.fetchone()\n",
    "    conn.close()\n",
    "    \n",
    "    if not row:\n",
    "        # table is empty, start from scratch\n",
    "\n",
    "        conn = sqlite3.connect(sqlitefile)\n",
    "        c = conn.cursor()\n",
    "        c.execute('''SELECT * FROM '''+candidate+''';''')\n",
    "        all_rows = c.fetchall()\n",
    "        conn.close()\n",
    "        \n",
    "        prev_time = None\n",
    "        sentiments = []\n",
    "        tweet_count = 0\n",
    "        for row in all_rows:\n",
    "            sentiments.append(row[1])\n",
    "            tweet_count += 1\n",
    "            if not prev_time:\n",
    "                prev_time = row[0]\n",
    "                continue\n",
    "            time = row[0]\n",
    "            if time - prev_time > bin_size:\n",
    "                # we've passed bin_size, wrap it up\n",
    "                if time - prev_time > bin_size*2:\n",
    "                    # more than 2 bin_sizes have passed, we're missing data. Add an empty entry.\n",
    "                    conn = sqlite3.connect(sqlitefile_downsampled)\n",
    "                    c = conn.cursor()\n",
    "                    c.execute('''INSERT INTO '''+candidate+'''(datetime, sentiment, tweet_count) VALUES (?,?,?);''',\n",
    "                             (time - (time-prev_time)/2, None, tweet_count))\n",
    "                    conn.commit()\n",
    "                    conn.close()\n",
    "                    prev_time = time\n",
    "                    sentiments = []\n",
    "                    tweet_count = 0\n",
    "                elif tweet_count >= min_tweets: # check if we have a reasonable number of tweets to get a mean sentiment from\n",
    "                    conn = sqlite3.connect(sqlitefile_downsampled)\n",
    "                    c = conn.cursor()\n",
    "                    c.execute('''INSERT INTO '''+candidate+'''(datetime, sentiment, tweet_count) VALUES (?,?,?);''',\n",
    "                             (time - (time-prev_time)/2, np.mean(sentiments), tweet_count))\n",
    "                    conn.commit()\n",
    "                    conn.close()\n",
    "                    prev_time = time\n",
    "                    sentiments = []\n",
    "                    tweet_count = 0\n",
    "        \n",
    "    else: # table is not empty\n",
    "        \n",
    "        conn = sqlite3.connect(sqlitefile_downsampled)\n",
    "        c = conn.cursor()\n",
    "        c.execute('''SELECT datetime FROM '''+candidate+''' ORDER BY rowid DESC LIMIT 1;''')\n",
    "        row = c.fetchone()\n",
    "        downsampled_lasttime = row[0]\n",
    "        conn.close()\n",
    "        \n",
    "        conn = sqlite3.connect(sqlitefile)\n",
    "        c = conn.cursor()\n",
    "        c.execute('''SELECT datetime FROM '''+candidate+''' ORDER BY rowid DESC LIMIT 1;''')\n",
    "        row = c.fetchone()\n",
    "        data_lasttime = row[0]\n",
    "        conn.close()\n",
    "        \n",
    "        if data_lasttime - downsampled_lasttime > bin_size:\n",
    "            \n",
    "            # time to add another datapoint\n",
    "\n",
    "            conn = sqlite3.connect(sqlitefile)\n",
    "            c = conn.cursor()\n",
    "            c.execute('''SELECT * FROM '''+candidate+''' WHERE datetime > '''+str(downsampled_lasttime)+''';''')\n",
    "            rows = c.fetchall()\n",
    "            conn.close()\n",
    "\n",
    "            prev_time = downsampled_lasttime\n",
    "            sentiments = []\n",
    "            tweet_count = 0\n",
    "            for row in rows:\n",
    "                sentiments.append(row[1])\n",
    "                tweet_count += 1\n",
    "                if not prev_time:\n",
    "                    prev_time = row[0]\n",
    "                    continue\n",
    "                time = row[0]\n",
    "                if time - prev_time > bin_size:\n",
    "                    # we've passed bin_size, wrap it up\n",
    "                    if time - prev_time > bin_size*2:\n",
    "                        # more than 2 bin_sizes have passed, we're missing data. Add an empty entry.\n",
    "                        conn = sqlite3.connect(sqlitefile_downsampled)\n",
    "                        c = conn.cursor()\n",
    "                        c.execute('''INSERT INTO '''+candidate+'''(datetime, sentiment, tweet_count) VALUES (?,?,?);''',\n",
    "                                 (time - (time-prev_time)/2, None, tweet_count))\n",
    "                        conn.commit()\n",
    "                        conn.close()\n",
    "                    elif tweet_count >= min_tweets: # check if we have a reasonable number of tweets to get a mean sentiment from\n",
    "                        conn = sqlite3.connect(sqlitefile_downsampled)\n",
    "                        c = conn.cursor()\n",
    "                        c.execute('''INSERT INTO '''+candidate+'''(datetime, sentiment, tweet_count) VALUES (?,?,?);''',\n",
    "                                 (time - (time-prev_time)/2, np.mean(sentiments), tweet_count))\n",
    "                        conn.commit()\n",
    "                        conn.close()\n",
    "                    \n",
    "                    prev_time = time\n",
    "                    sentiments = []\n",
    "                    tweet_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viral tweet detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentiment_diff_threshold = 0.071834651618471426 # two times the standard deviation of all data up to April 16th 2016\n",
    "# tps_diff_threshold = 4259.3176542475112 # two times the standard deviation of all data up to April 16th 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidate = 'sanders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff_smooth(x, n):\n",
    "    a = np.zeros_like(x)\n",
    "    for i in range(len(x)-n):\n",
    "        i += n\n",
    "        a[i] = np.nanmean(x[i:i+n], axis=0) - np.nanmean(x[i-n:i], axis=0)\n",
    "    return a\n",
    "\n",
    "def get_peaks(x, threshold):\n",
    "    peaks = []\n",
    "    peaking = False\n",
    "    start = None\n",
    "    for a in x:\n",
    "        if not peaking:\n",
    "            if a[1] > threshold:\n",
    "                start = a[0]\n",
    "                peaking = True\n",
    "        elif peaking:\n",
    "            if a[1] < threshold:\n",
    "                end = a[0]\n",
    "                peaks.append([start, end])\n",
    "                start = None\n",
    "                peaking = False\n",
    "    return np.array(peaks)\n",
    "\n",
    "# get downsampled data\n",
    "conn = sqlite3.connect(sqlitefile_downsampled)\n",
    "c = conn.cursor()\n",
    "c.execute('''SELECT * FROM '''+candidate+''' LIMIT 1;''')\n",
    "rows = c.fetchall()\n",
    "conn.close()\n",
    "\n",
    "rows = np.array(rows)\n",
    "\n",
    "# calculate derivative of sentiment and tweets per bin\n",
    "data_diff = rows.copy()\n",
    "data_diff[:,1] = diff_smooth(rows[:,1], 3)\n",
    "data_diff[:,2] = diff_smooth(rows[:,2], 3)\n",
    "\n",
    "# get peaks above a threshold\n",
    "sentiment_diff_threshold = np.std(data_diff[:,1])*2\n",
    "tps_diff_threshold = np.std(data_diff[:,2])*2\n",
    "sentiment_diff_peaks = get_peaks(data_diff[:,[0,1]], sentiment_diff_threshold)\n",
    "tps_diff_peaks = get_peaks(data_diff[:,[0,2]], tps_diff_threshold)\n",
    "\n",
    "# find most common tweetID of each peak\n",
    "peaks = np.sort(np.vstack((sentiment_diff_peaks, tps_diff_peaks)), axis=0)\n",
    "top_tweets = []\n",
    "prev_top_tweet = None\n",
    "for p in peaks:\n",
    "    \n",
    "    # get most common tweetID during the peak\n",
    "    conn = sqlite3.connect(sqlitefile)\n",
    "    c = conn.cursor()\n",
    "    c.execute('''\n",
    "    SELECT datetime, tweetID FROM '''+candidate+'''\n",
    "    WHERE datetime > '''+str(p[0])+'''\n",
    "    AND datetime < '''+str(p[1])+'''\n",
    "    GROUP BY X\n",
    "    HAVING COUNT(*) = (\n",
    "                       SELECT MAX(Cnt) \n",
    "                       FROM(\n",
    "                             SELECT COUNT(*) as Cnt\n",
    "                             FROM yourTable\n",
    "                             GROUP BY X\n",
    "                            ) tmp\n",
    "                        )\n",
    "    LIMIT 1;\n",
    "    ''')\n",
    "    row = c.fetchone()\n",
    "    conn.close()\n",
    "    \n",
    "    if len(row) < 1:\n",
    "        continue\n",
    "        \n",
    "    top_tweet = row[1]\n",
    "    datetime = row[0]\n",
    "        \n",
    "    # check if same tweet as previous peak\n",
    "    if prev_top_tweet and top_tweet == prev_top_tweet:\n",
    "        continue\n",
    "    prev_top_tweet = top_tweet\n",
    "    top_tweets.append({'datetime': datetime), 'tweetID': top_tweet})\n",
    "\n",
    "# print top_tweets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
